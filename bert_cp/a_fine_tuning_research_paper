test_size = 0.25 --> pour choisir params
puis entrainement ac 0.01

verifier que taskname posos = ok

batch size: [16,32]  --> essayer aussi ac 8
learning rate: [2e-5, 3e-5, 5e-5]  --> essayer aussi ac 1e-5
nb of epochs [2,3,4] essayer aussi 5


noter le temps a chaque fois

rajouter une epoch 3 a 4 a augmente de 1 a 3 %

processors = {
     "cola": ColaProcessor,
     "mnli": MnliProcessor,
     "mrpc": MrpcProcessor,
     "xnli": XnliProcessor,
     "selfsim": SelfProcessor #添加自己的processor
  }

max seq length 64 ?


python run_classifier.py \
--task_name=posos \
--do_train=true \
--do_eval=true \
--do_predict=true \
--data_dir=./data/ \
--vocab_file=./multi_cased_L-12_H-768_A-12/vocab.txt \
--bert_config_file=./multi_cased_L-12_H-768_A-12/bert_config.json \
--init_checkpoint=./multi_cased_L-12_H-768_A-12/bert_model.ckpt --max_seq_length=128 \
--train_batch_size=32 \
--learning_rate=5e-6 \
--num_train_epochs=8.0 \
--output_dir=./output_4/ \
--do_lower_case=False


python run_classifier.py \
--task_name=cola \
--do_predict=true \
--data_dir=./data \
--vocab_file=./multi_cased_L-12_H-768_A-12/vocab.txt \
--bert_config_file=./multi_cased_L-12_H-768_A-12/bert_config.json \
--init_checkpoint=./output_4/model.ckpt-3000 \
--max_seq_length=128 \
--output_dir=./output_4/

